
\documentclass[letterpaper,reqno,12pt]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{color,latexsym,amsmath,amssymb}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage[linesnumbered,lined,boxed,commentsnumbered,noend,noline]{algorithm2e}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage[numbers]{natbib}
\usepackage{listings}% http://ctan.org/pkg/listings
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  mathescape
}

\setlength{\AlCapSkip}{0.5em}

\allowdisplaybreaks

\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\mynote}[3][red]
  {{\color{#1} \fbox{\bfseries\sffamily\scriptsize#2}
  {\small$\blacktriangleright$\textsf{\emph{#3}}$\blacktriangleleft$}}~}
\newcommand{\yp}[1]{\mynote{YP}{#1}}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\charcone}{char.cone}
\DeclareMathOperator{\STAB}{STAB}
\DeclareMathOperator{\Down}{Down}
\DeclareMathOperator{\lca}{lca}
\DeclareMathOperator{\LPO}{LPO}
\DeclareMathOperator{\OPT}{OPT}
\DeclareMathOperator{\LHS}{LHS}
\DeclareMathOperator{\RHS}{RHS}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\poly}{poly}
\begin{document}
\pagenumbering{arabic}
\title{Network Flow Algorithms: Exercise Solutions}
\author{Yuchong Pan}
\date{\today}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\theoremstyle{definition} \newtheorem{exercise}{Exercise} [section]
\theoremstyle{definition} \newtheorem{defn}{Definition}
\maketitle
%

\section{Preliminaries: Shortest Path Algorithms}

\begin{exercise}
  Let $i_k$ be the vertex selected at the $k^\text{th}$ iteration of Dijkstra's algorithm. We prove by induction that at the beginning of the $k^\text{th}$ iteration, $d(v) \in \{ d(i_k), d(i_k) + 1, \infty \}$ for all $v \in V$ not marked yet. At the beginning of the first iteration, $s$ is selected, and any $v \in V$ has $d(v) = \infty$; this proves the base case.
  
  Suppose that at the beginning of the $k^\text{th}$ iteration, $d(v) \in \{ d(i_k), d(i_k) + 1, \infty \}$ for all $v \in V$ not marked yet. Let $(i_k, j) \in A$ such that $j$ is not marked yet. If $d(i_k) + c(i_k, j) = d(i_k) + 1 < d(j)$, then we set $d(j) \leftarrow d(i_k) + 1$; otherwise, $d(j)$ remains the same, and hence $d(j) \in \{ d(i_k), d(i_k) + 1, \infty \}$. If $d(i_{k + 1}) = d(i_k)$, then we are done; otherwise, $d(i_{k + 1}) = d(i_k) + 1$, and $d(v) \in \{ d(i_k) + 1, \infty \} = \{ d(i_{k + 1}), \infty \}$ for all $v \in V$ not marked yet. This completes the induction step.

  Now, consider the $k^\text{th}$ iteration. If $d(i_k) + c(i_k, j) = d(i_k) + 1 < d(j)$ for some $(i, j) \in A$, then $d(j)$ was $\infty$, and we set $d(j) \leftarrow d(i_k) + 1$. Since $d(v) \in \{ d(i_k), d(i_k) + 1, \infty \}$ for all $v \in V$ not marked yet, then we can process $j$ after any $v \in V$ not marked yet such that $d(v) < \infty$ is processed. Therefore, we can maintain a queue of all $v \in V$ not marked yet such that $d(v) < \infty$, and we push $j$ to the tail of the queue if $d(j)$ is updated. The adapted algorithm is given in Algorithm \ref{alg:adapted-dijkstra}. It is clear that Algorithm \ref{alg:adapted-dijkstra} runs in $O(m)$ time.

  \begin{algorithm}
    $q \leftarrow \textit{new queue()}$ \\
    $d(i) \leftarrow \infty$ for all $i \in V$ \\
    $p(i) \leftarrow \textbf{null}$ for all $i \in V$ \\
    $d(s) \leftarrow 0$ \\
    $q.\textit{add($s$)}$ \\
    \While{not $q.\textit{empty?}$}{
      $i \leftarrow q.\textit{remove()}$ \\
      \For{$j \in V$ such that $(i, j) \in A$}{
        \If{$d(j) > d(i) + 1$}{
          $d(j) \leftarrow d(i) + 1$ \\
          $p(j) \leftarrow i$ \\
          $q.\textit{add($j$)}$
        }
      }
    }
    \caption{Adapted Dijkstra's algorithm where $c(i, j) = 1$ for all $(i, j) \in A$.}
    \label{alg:adapted-dijkstra}
  \end{algorithm}
\end{exercise}

\begin{exercise} \label{ex:shortest-existence}
  ($\Longrightarrow$) Suppose for the sake of contradiction that there exists a negative-cost cycle $C$ reachable from $s$. Let $v \in V(C)$. Let $\mathcal P$ be the set of $s$-$v$ paths. Let $P_0 \in \mathcal P$. Let $P'$ be a $v$-$v$ path along $C$. Then $P_0$ appended by any copy of $P'$ is an $s$-$v$ path. Since $c(P') := \sum_{e \in E(P')} c(e) < 0$, then $\{ c(P) := \sum_{e \in E(P)} c(e) : P \in \mathcal P \}$ is not bounded below. Hence, there are no simple shortest $s$-$v$ paths.

  ($\Longleftarrow$) Suppose that there are no negative-cost cycles reachable from $s$. Let $i \in V$. Let $\mathcal P$ be the set of simple $s$-$i$ paths. Since a simple $s$-$i$ path consists of at most $n$ distinct vertices, then $|P| \leq n! < \infty$. Let $P^* = \argmin_{P \in \mathcal P} c(P) := \argmin_{P \in \mathcal P} \sum_{e \in E(P)} c(e)$. Let $P$ be a non-simple $s$-$i$ path. Then $P$ contains a cycle $C$. Since there are no negative-cost cycles reachable from $s$, then $c(C) := \sum_{e \in E(C)} c(e) \geq 0$. This implies that removing all occurrences of $C$ from $P$ yields a simple $s$-$i$ path $P'$ with $c(P) \geq c(P') \geq \min \{ c(P) : P \in \mathcal P \} = c(P^*)$. Hence, $c(P^*) \leq c(P)$ for any $s$-$i$ path $P$, regardless of whether $P$ is simple or not. This shows that $P^*$ is the shortest $s$-$i$ path, and $P^*$ is simple.
\end{exercise}

\begin{exercise}
  \begin{enumerate}
    \item[(a)] Let $G = (V, A)$ be a DAG. Suppose for the sake of contradiction that any $v \in V$ has at least an arc directed into it. Let $v_0 \in V$. Starting from $v_0$, we form a path backwards by following an edge directed into the vertices. By the pigeonhole principle, this forms a path with repeated vertices, say $\{ (v_0, v_1), (v_1, v_2), \ldots, (v_{k - 1}, v_k) \}$, where $v_k = v_j$ for some $j \in \{ 0, \ldots, k - 2 \}$. Then $\{ (v_j, v_{j + 1}), (v_{j + 1}, v_{j + 2}), \ldots, (v_{k - 1}, v_k) \}$ is a directed cycle, a contradiction.
    \item[(b)] Let $G = (V, A)$. Let $c : A \to \RR$ be the edge costs. We give Algorithm \ref{alg:dag-shortest}.

    \begin{algorithm}
      $q \leftarrow \textit{new queue()}$ \\
      $d(i) \leftarrow \infty$ for all $i \in V$ \\
      $p(i) \leftarrow \textbf{null}$ for all $i \in V$ \\
      $d(s) \leftarrow 0$ \\
      $q.\textit{add($s$)}$ \\
      \While{not $q.\textit{empty?}$}{
        $i \leftarrow q.\textit{remove()}$ \\
        \For{$j \in V$ such that $(i, j) \in A$}{
          \If{$d(j) > d(i) + c(i, j)$}{
            $d(j) \leftarrow d(i) + c(i, j)$ \\
            $p(j) \leftarrow i$ \\
          }
          \If{not $q.\textit{contains($j$)}$}{
            $q.\textit{add($j$)}$
          }
        }
      }
      \caption{{\tt DAGShortest($G$, $c$, $s$)} for finding the shortest $s$-$i$ path for each $i \in V$ in a DAG $G$.}
      \label{alg:dag-shortest}
    \end{algorithm}

    Since $G$ is a DAG, then $G$ does not contain negative-cost cycles. By Exercise \ref{ex:shortest-existence}, there are simple shortest paths from $s$ to each $i \in V$. We will prove that Algorithm \ref{alg:dag-shortest} determines the length $d(i)$ of the shortest $s$-$i$ path for all $i \in V$ by induction on the ``passes.'' Pass $0$ ends after $s$ is added to the queue, and pass $k$ ends after any $i \in V$ such that the shortest $s$-$i$ path uses at most $k$ edges. The base case is trivial since the only $s$-$s$ path is of length $0$.

    Suppose that after pass $k$ for some $k$, $d(i)$ is the length of the shortest $s$-$i$ path for any $i \in V$ such that the shortest $s$-$i$ path uses at most $k$ edges. Let $i \in V$ such that the shortest $s$-$i$ path $P$ uses $k + 1$ edges. Let $(j, i)$ be the last edge on $P$. Let $P'$ be the subpath of $P$ up to $j$. Then $P'$ is the shortest $s$-$j$ path. By the induction hypothesis, $c(P') = d(j)$. Therefore, $d(i)$ is set to $d(j) + c(j, i) = c(P') + c(j, i) = c(P)$ when Algorithm \ref{alg:dag-shortest} processes $j$. This proves the claim.
    \item[(c)] Let $G = (V, A)$. Let $c : A \to \RR$ be the edge costs. We give Algorithm \ref{alg:dag-longest}. Let $i \in V$. Note that $\max \{ c(P) : P \text{ is an $s$-$i$ path} \} = -\min \{ -c(P) : P \text{ is an $s$-$i$ path} \}$.

    \begin{algorithm}
      $(d', p) \leftarrow \texttt{DAGShortest($G, -c, s$)}$ \\
      $d(i) \leftarrow -d'(i)$ for all $i \in V$
      \caption{{\tt DAGLongest($G$, $c$, $s$)} for finding the longest $s$-$i$ path for each $i \in V$ in a DAG $G$.}
      \label{alg:dag-longest}
    \end{algorithm}
  \end{enumerate}
\end{exercise}

\begin{exercise}
  \yp{We re-define $d_k(j)$ to be the length of the shortest $s$-$j$ path of length $k$, as in R.\ M.\ Karp's original paper.}
  Let $c' = c - \mu$. Let $\Gamma_0$ be a cycle of $G$. Then we have that
  \begin{align*}
    c'\left(\Gamma_0\right) &= \sum_{e \in E\left(\Gamma_0\right)} c'(e) = \sum_{e \in E\left(\Gamma_0\right)} (c(e) - \mu) = \sum_{e \in E\left(\Gamma_0\right)} c(e) - \left|\Gamma_0\right| \mu = c\left(\Gamma_0\right) - \left|\Gamma_0\right| \min_{\text{cycle $\Gamma$ of $G$}} \frac{c(\Gamma)}{|\Gamma|} \\
    &\geq c\left(\Gamma_0\right) - \left|\Gamma_0\right| \cdot \frac{c\left(\Gamma_0\right)}{\left|\Gamma_0\right|} = c\left(\Gamma_0\right) - c\left(\Gamma_0\right) = 0.
  \end{align*}
  This shows that $G$ with edge costs $c'$ does not have negative-cost cycles. Hence, the Bellman-Ford algorithm correctly computes the shortest $s$-$j$ paths for all $j \in V$. Let $d_k'(j)$ be the length of the shortest $s$-$j$ path of length $k$ with edge costs $c'$. By Exercise 1.2, there exists a simple shortest path $P_j$ from $s$ to any $j \in V$, which is of length $< n$. Hence, $c'(P_j) = \min_{0 \leq k \leq n - 1} d_k'(j)$ and $c'(P_j) \leq d_n'(j)$ for all $j \in V$. This implies that $d_n'(j) \geq \min_{0 \leq k \leq n - 1} d_k'(j)$ for all $j \in V$. On the other hand, let $\Gamma^* = \argmin_{\text{cycle $\Gamma$ of $G$}} \frac{c(\Gamma)}{|G|}$. Then we have that
  $$ c'\left(\Gamma^*\right) = c\left(\Gamma^*\right) - \left|\Gamma^*\right| \min_{\text{cycle $\Gamma$ of $G$}} \frac{c(\Gamma)}{|\Gamma|} = c\left(\Gamma^*\right) - \left|\Gamma^*\right| \cdot \frac{c\left(\Gamma^*\right)}{\left|\Gamma^*\right|} = c\left(\Gamma^*\right) - c\left(\Gamma^*\right) = 0. $$
  Let $v \in V(\Gamma^*)$. Let $P$ be a simple shortest $s$-$v$ path. Then $|P| < n$. Let $\ell \in \NN$ be such that $|P| + \ell |\Gamma^*| \geq n$. Then the path $P'$ formed by appending $\ell$ copies of $\Gamma^*$ to the end of $P$ is also a shortest $s$-$v$ path. Hence, the subpath $P''$ of $P'$ formed by the first $n$ edges of $P'$, which is an $s$-$v^*$ path for some $v^* \in V$, is a shortest $s$-$v^*$ path. Therefore, $d_n'(v^*) = c'(P'') = \min_{0 \leq k \leq n - 1} d_k'(v^*)$. This proves that
  $$ \min_{j \in V} \max_{0 \leq k \leq n - 1} \frac{d_n'(j) - d_k'(j)}{n - k} = 0. $$
  Let $j \in V$. Let $0 \leq k \leq n$. Let $P$ be a shortest $s$-$j$ path of length $k$. Then $d_k(j) = c(P)$. It is clear that $P$ is also a shortest $s$-$j$ path of length $k$ with edge costs $c'$. Hence, $d_k'(j) = c'(P)$. Since $d_k(j)$ is a path of length $k$, then we have that
  \begin{align*}
    d_k(j) &= c(P) = \sum_{e \in E(P)} c(e) = \sum_{e \in E(P)} (c(e) - \mu + \mu) = \sum_{e \in E(P)} (c(e) - \mu) + |P| \mu \\
    &= \sum_{e \in E(P)} c'(e) + k \mu = c'(P) + k\mu = d_k'(j) + k\mu.
  \end{align*}
  Hence, we have that
  \begin{align*}
    \min_{j \in V} \max_{0 \leq k \leq n - 1} \frac{d_n(j) - d_k(j)}{n - k} &= \min_{j \in V} \max_{0 \leq k \leq n - 1} \frac{\left(d_n'(j) + n\mu\right) - \left(d_k'(j) + k\mu\right)}{n - k} \\
    &= \min_{j \in V} \max_{0 \leq k \leq n - 1} \frac{d_n'(j) - d_k'(j) + (n - k) \mu}{n - k} \\
    &= \min_{j \in V} \max_{0 \leq k \leq n - 1} \left(\frac{d_n'(j) - d_k'(j)}{n - k} + \mu\right) \\
    &= \min_{j \in V} \max_{0 \leq k \leq n - 1} \frac{d_n'(j) - d_k'(j)}{n - k} + \mu \\
    &= 0 + \mu = \mu.
  \end{align*}

  Next, we show that $d_k(j)$ can be computed by the following recurrence:
  \begin{equation} \label{eq:bellman-ford-recurrence}
    d_k(j) = \left\{
    \begin{array}{ll}
      \min_{(i, j) \in E} \left(d_{k - 1}(i) + c(i, j)\right), & k > 0, \\
      0, & k = 0, j = s, \\
      \infty, & k = 0, j \neq s.
    \end{array}
  \right.
  \end{equation}
  It is clear that $d_0(s) = 0$ and $d_0(j) = \infty$ for all $j \in V \setminus \{ s \}$. Let $1 \leq k \leq n$. Let $j \in V$. Let $P$ be a shortest $s$-$j$ path of length $k$. Let $(i^*, j)$ be the last edge of $P$. Then the subpath $P'$ formed by all edges of $P$ except $(i^*, j)$ is a shortest $s$-$i^*$ path of length $k - 1$. Hence, $c(P') = d_{k - 1}(i^*)$. This implies that
  $$ d_k(j) = c(P) = c(P') + c(i^*, j) = d_{k - 1}(i^*) + c(i^*, j) \geq \min_{(i, j) \in E} \left(d_{k - 1}(i) + c(i, j)\right). $$
  For all $(i, j) \in E$, if $P_i$ is a shortest $s$-$i$ path of length $k - 1$, then $P_i$ appended by $(i, j)$ is an $s$-$j$ path, so $d_{k - 1}(i) + c(i, j) = c(P_i) + c(i, j) \geq d_k(j)$. This implies that $\min_{(i, j) \in E} (d_{k - 1}(i) + c(i, j)) \geq d_k(j)$. This proves \eqref{eq:bellman-ford-recurrence}. We give Algorithm \ref{alg:min-mean-cost-cycle} to compute $\mu$ and a cycle $\Gamma$ such that $\mu = \frac{c(\Gamma)}{|\Gamma|}$. It is clear that the running time of Algorithm \ref{alg:min-mean-cost-cycle} is $O(nm)$. It remains to show that $\Gamma^*$ returned by Algorithm \ref{alg:min-mean-cost-cycle} satisfies $\frac{c(\Gamma^*)}{|\Gamma^*|} = \mu$. We note that $p_k(j)$ stores a shortest $s$-$j$ path of length $k$ by following $p_k(j)$ backwards. Hence, $P$ is a shortest $s$-$j^*$ path of length $n$. This implies that $P$ is not simple and hence contains at least one cycle. Since $\frac{d_n(j^*) - d_{k^*}(j^*)}{n - k^*} = \mu$, then we have that
  \begin{align*}
    \frac{d_n'\left(j^*\right) - d_{k^*}'\left(j^*\right)}{n - k^*} &= \frac{\left(d_n\left(j^*\right) - n\mu\right)- \left(d_{k^*}\left(j^*\right) - k^* \mu\right)}{n - k^*} = \frac{d_n\left(j^*\right) - d_{k^*}\left(j^*\right) - \left(n - k^*\right) \mu}{n - k^*} \\
    &= \frac{d_n\left(j^*\right) - d_{k^*}\left(j^*\right)}{n - k^*} - \mu = \mu - \mu = 0.
  \end{align*}
  This implies that $d_n'(j^*) = d_{k^*}'(j^*) = \min_{0 \leq k \leq n - 1} d_k'(j^*)$ is the length of the shortest $s$-$j^*$ path. Hence, cycle $\Gamma^*$ contained in $P$ must have cost $0$ with edge costs $c'$. Otherwise, we could have eliminated $\Gamma^*$ to get a lower cost. We have that
  \begin{align*}
    \frac{c\left(\Gamma^*\right)}{\left|\Gamma^*\right|} &= \frac{\sum_{e \in E\left(\Gamma^*\right)} c(e)}{\left|\Gamma^*\right|} = \frac{\sum_{e \in E\left(\Gamma^*\right)} (c(e) - \mu + \mu)}{\left|\Gamma^*\right|} = \frac{\sum_{e \in E\left(\Gamma^*\right)} (c(e) - \mu) + \left|\Gamma^*\right| \mu}{\left|\Gamma^*\right|} \\
    &= \frac{\sum_{e \in E\left(\Gamma^*\right)} c'(e)}{\left|\Gamma^*\right|} + \mu = \frac{c'\left(\Gamma^*\right)}{\left|\Gamma^*\right|} + \mu = \frac{0}{\left|\Gamma^*\right|} + \mu = 0 + \mu = \mu.
  \end{align*}
  This completes the proof.

  \begin{algorithm}
    $d_k(j) \leftarrow \infty$ for all $0 \leq k \leq n, j \in V$ \\
    $d_0(s) \leftarrow 0$ \\
    $p_k(j) \leftarrow \textbf{null}$ for all $0 \leq k \leq n, j \in V$ \\
    \For{$k \leftarrow 1, \ldots, n$}{
      \For{$(i, j) \in E$}{
        \If{$d_{k - 1}(i) + c(i, j) < d_k(j)$}{
          $d_k(j) \leftarrow d_{k - 1}(i) + c(i, j)$ \\
          $p_k(j) \leftarrow i$
        }
      }
    }
    $\mu \leftarrow \infty$ \\
    \For{$j \in V$}{
      $\nu \leftarrow -\infty$ \\
      \For{$k \leftarrow 0, \ldots, n - 1$}{
        $\nu \leftarrow \max(\nu, \frac{d_n(j) - d_k(j)}{n - j})$
      }
      \If{$\nu < \mu$}
      {
        $\mu \leftarrow \nu$ \\
        $j^* \leftarrow j$
      }
    }
    $P = \{ (v_1, v_2), \ldots, (v_{n - 1}, v_n) \} \leftarrow \text{path formed by following $p_n$ from $j^*$ backwards}$ \\
    \For{$p \leftarrow 1, \ldots, n - 1$}{
      \For{$q \leftarrow p + 1, \ldots, n$}{
        \If{$v_p = v_q$}{
          \Return{$\Gamma^* = \{ (v_p, v_{p + 1}), \ldots, (v_{q - 1}, v_q) \}$}
        }
      }
    }
    \caption{An algorithm for computing the minimum mean-cost cycle.}
    \label{alg:min-mean-cost-cycle}
  \end{algorithm}
\end{exercise}

\begin{exercise}
  \begin{enumerate}
    \item[(a)] We give Algorithm \ref{alg:min-cost-time-ratio-cycle}. Let $k$ be the number of iterations in the binary search of Algorithm \ref{alg:min-cost-time-ratio-cycle}. Then $k$ is the minimum positive integer such that $\frac{(nC + 1) - (-nC)}{2^k} < \frac{1}{(nT)^2}$, i.e.\ $2^k > (2nC + 1)(nT)^2$. Hence, we have that
    \begin{align*}
      k &= \left\lceil \log_2 \left((2nC + 1)(nT)^2\right) \right\rceil + 1 = O\left(\log \left(nC (nT)^2\right)\right) = O\left(\log \left(n^3 CT^2\right)\right) \\
      &= O(3\log n + \log C + 2\log T) = O(\log n + \log C + \log T) = O(\log (nCT)).
    \end{align*}
    In each iteration, we invoke the negative-cost cycle detection algorithm, whose running time is $O(nm)$. Hence, the total running time of Algorithm \ref{alg:min-cost-time-ratio-cycle} is $O(nm\log(nCT))$.

    \begin{algorithm}
      $\ell \leftarrow -nC$ \\
      $u \leftarrow nC + 1$ \\
      \While{$u - \ell \geq \frac{1}{(nT)^2}$}{
        $\mu \leftarrow \frac{\ell + u}{2}$ \\
        Check whether $G$ has negative-cost cycles with edge costs $c - \mu t$ \\
        \If{there exists a negative-cost cycle of $G$ with edge costs $c - \mu t$}{
          $u \leftarrow \mu$
        }
        \Else{
          $l \leftarrow \mu$
        }
      }
      Find a negative-cost cycle $\Gamma^*$ of $G$ with edge costs $c - ut$ \\
      \Return{$\Gamma^*$}
      \caption{An algorithm for finding a cycle that minimizes $\min_\text{cycle $\Gamma$ of $G$} \frac{c(\Gamma)}{t(\Gamma)}$.}
      \label{alg:min-cost-time-ratio-cycle}
    \end{algorithm}

    Let
    $$ \mu^* = \min_\text{cycle $\Gamma$ of $G$} \frac{c(\Gamma)}{t(\Gamma)}. $$
    We will show that $\ell \leq \mu^* < u$ by induction on the iterations of the binary search. Let $\Gamma$ be a cycle of $G$. Then $|\Gamma| \leq n$. Since $t(\Gamma_j) = \sum_{e \in E(\Gamma_j)} t(e) \in \NN$, then we have that
    $$ \left|\frac{c(\Gamma)}{t(\Gamma)}\right| = \frac{|c(\Gamma)|}{t(\Gamma)} \leq \frac{\left|\sum_{e \in E(\Gamma)} c(e)\right|}{1} \leq \sum_{e \in E(\Gamma)} |c(e)| \leq \sum_{e \in E(\Gamma)} C = |\Gamma| C \leq nC. $$
    This shows that $-nC \leq \mu^* \leq nC < nC + 1$, proving the base case. Let $\ell_0, u_0$ be the values of $\ell, u$ in some iteration. Let $\ell', u'$ be the values of $\ell, u$ in the next iteration. If $G$ has a negative-cost cycle $\Gamma$ with edge costs $c - \mu t$, then $c(\Gamma) - \mu t(\Gamma) < 0$ and hence $\frac{c(\Gamma)}{t(\Gamma)} < \mu$; this implies that $\mu^* < \mu$. Otherwise, $c(\Gamma) - \mu t(\Gamma) \geq 0$ and hence $\frac{c(\Gamma)}{t(\Gamma)} \geq \mu$ for any cycle $\Gamma$ of $G$; this implies that $\mu^* \geq \mu$. This completes the induction step.

    Let $\ell^*, u^*$ be the final values of $\ell, u$. We will show that the cycle $\Gamma^*$ returned by Algorithm \ref{alg:min-cost-time-ratio-cycle} satisfies $\frac{c(\Gamma^*)}{t(\Gamma^*)} = \mu^*$. Note that
    $$ \frac{c\left(\Gamma^*\right)}{t\left(\Gamma^*\right)} \geq \min_\text{cycle $\Gamma$ of $G$} \frac{c(\Gamma)}{t(\Gamma)} = \mu^*. $$
    Suppose for the sake of contradiction that $\frac{c(\Gamma^*)}{t(\Gamma^*)} > \mu^*$. Then $c(\Gamma^*) > \mu^* t(\Gamma^*)$.
    By Algorithm \ref{alg:min-cost-time-ratio-cycle}, $c(\Gamma^*) - u^* t(\Gamma^*) < 0$, and hence $c(\Gamma^*) < u^* t(\Gamma)$. Combining these two inequalities gives that $\mu^* t(\Gamma^*) < c(\Gamma^*) < u^* t(\Gamma^*)$. Hence, we have that $\mu^* < \frac{c(\Gamma^*)}{t(\Gamma^*)} < u^*$. This implies that
    \begin{equation} \label{eq:cost-time-ratio-difference}
      \frac{c(\Gamma^*)}{t(\Gamma^*)} - \mu^* < u^* - \mu^* \leq u^* - \ell^* < \frac{1}{(nT)^2}.
    \end{equation}
    Let
    $$ \Gamma' = \argmin_\text{cycle $\Gamma$ of $G$} \frac{c(\Gamma)}{t(\Gamma)}. $$
    For any cycle $\Gamma$ of $G$, we have that
    $$ t(\Gamma) = \sum_{e \in E(\Gamma)} t(e) \leq \sum_{e \in E(\Gamma)} T = |\Gamma| T \leq nT. $$
    Since $\frac{c(\Gamma^*)}{t(\Gamma^*)} > \mu^*$ and since $c(i, j), t(i, j) \in \ZZ$, then we have that
    $$ \frac{c\left(\Gamma^*\right)}{t\left(\Gamma^*\right)} - \mu^* = \frac{c\left(\Gamma^*\right)}{t\left(\Gamma^*\right)} - \frac{c\left(\Gamma'\right)}{t\left(\Gamma'\right)} = \frac{c\left(\Gamma^*\right) t\left(\Gamma'\right) - c\left(\Gamma'\right) t\left(\Gamma^*\right)}{t\left(\Gamma^*\right) t\left(\Gamma'\right)} \geq \frac{1}{t\left(\Gamma^*\right) t\left(\Gamma'\right)} \geq \frac{1}{(nT)^2}. $$
    This contradicts \eqref{eq:cost-time-ratio-difference}. Hence, $\frac{c(\Gamma^*)}{t(\Gamma^*)} = \mu^*$. The proof is complete.
  \end{enumerate}
\end{exercise}

\end{document}
